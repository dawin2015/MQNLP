## 一种词典生成方法
> 方法参考了：http://www.matrix67.com/blog/archives/5044

> 代码参考了：https://github.com/Moonshile/ChineseWordSegmentation 修改后使用与python3

## 注意
 - 该方法生成的字典需要大规模的语料库来训练，小语料库学习到的词典并没有原始文章说的那么好，如果看中AUC矩阵得分的童鞋，这个方法并不适用，因为得分会很低，但是词典的结果却是比例如使用人民币报训练出来的结果要更为的理想化，因为其不仅可以识别出人名等，还可以识别出chunk。

 - 计算瓶颈感觉是出现在了统计上面，后面有时间将采用spark改写统计词频/粘合度计算等问题上。